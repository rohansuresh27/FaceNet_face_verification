{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.7403714656829834 seconds importing libraries ---\n",
      "--- 1.8600242137908936 seconds to import other files ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from keras import backend as K\n",
    "from multiprocessing.dummy import Pool\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "print(\"--- %s seconds importing libraries ---\" % (time.time() - start_time))\n",
    "\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "capture_current_image = False\n",
    "\n",
    "print(\"--- %s seconds to import other files ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.304805278778076 seconds to load model ---\n",
      "--- 5.336719512939453 seconds to compile model ---\n",
      "--- 73.6858742237091 seconds to load weights ---\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))  #(3, 196, 196)\n",
    "print(\"--- %s seconds to load model ---\" % (time.time() - start_time))\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "print(\"--- %s seconds to compile model ---\" % (time.time() - start_time))\n",
    "\n",
    "load_weights_from_FaceNet(FRmodel)\n",
    "print(\"--- %s seconds to load weights ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PRESENT IMAGE \n",
    "\n",
    "def capture_img():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    cv2.namedWindow(\"Live Frame\")\n",
    "    print(\"--- Hit Space Bar to take Image ---\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        cv2.imshow(\"Live Frame\", frame)\n",
    "        if not ret:\n",
    "            break\n",
    "        k = cv2.waitKey(1)\n",
    "        \n",
    "        if k%256 == 32: #remove this if image to be taken automatically\n",
    "            # SPACE pressed\n",
    "            img_name = \"Your_present_Image_1.jpg\"\n",
    "            ref_img = cv2.imwrite(img_name, frame)\n",
    "            print(\"***** Your Image Taken for Verification !! *****\")\n",
    "        \n",
    "            print(\"--- Space Bar hit, closing... ---\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    your_image1 = cv2.imread('Your_present_Image_1.jpg', 1)\n",
    "    face_cascade1 = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    face1 = face_cascade1.detectMultiScale(your_image1, 1.3, 5)  ##\n",
    "\n",
    "    for (x,y,w,h) in face1:\n",
    "        imgg = cv2.rectangle(your_image1,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "        roi_color1 = imgg[y:y+h, x:x+w]\n",
    "        roi_color1 = cv2.resize(roi_color1, (96, 96))\n",
    "        cv2.imwrite('Your_present_img.jpg',roi_color1)\n",
    "        # get encoding\n",
    "        current_encoding = img_to_encoding(roi_color1, FRmodel)\n",
    "        \n",
    "    return current_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK IF REFERENCE IMAGE PRESENT IN DIRECTORY, ELSE SET REF IMAGE AND ITS ENCODING\n",
    "\n",
    "def check_ref():\n",
    "    \n",
    "    if os.path.isfile('C:/Users/RS_Vulcan/face_recognition/Your_ref_Image.jpg') is True:\n",
    "        print(\"--- %s seconds checking reference image ---\" % (time.time() - start_time))\n",
    "        current_encoding = capture_img()\n",
    "    else:\n",
    "        #SET REFERENCE IMAGE\n",
    "        def set_ref_img(): \n",
    "            cam = cv2.VideoCapture(0)\n",
    "\n",
    "            cv2.namedWindow(\"Live Frame\")\n",
    "            print(\"--- Hit Space Bar to take Image ---\")\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cam.read()\n",
    "                cv2.imshow(\"Live Frame\", frame)\n",
    "                if not ret:\n",
    "                    break\n",
    "                k = cv2.waitKey(1)\n",
    "\n",
    "                if k%256 == 32:\n",
    "                    # SPACE pressed\n",
    "                    img_name = \"Your_ref_Image_1.jpg\"\n",
    "                    ref_img = cv2.imwrite(img_name, frame)\n",
    "                    print(\"***** Your Reference Image Set !! *****\")\n",
    "        \n",
    "                    print(\"--- Space Bar hit, closing... ---\")\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "                    \n",
    "            your_image = cv2.imread('Your_ref_Image_1.jpg', 1)\n",
    "            face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "            face = face_cascade.detectMultiScale(your_image, 1.3, 5)\n",
    "\n",
    "            for (x,y,w,h) in face:\n",
    "                img = cv2.rectangle(your_image,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                roi_color = cv2.resize(roi_color, (96, 96))\n",
    "                cv2.imwrite('Your_ref_Image.jpg',roi_color)\n",
    "                # get encoding\n",
    "                ref_data = img_to_encoding(roi_color, FRmodel)\n",
    "            \n",
    "            print(ref_data)\n",
    "            \n",
    "            # save encoding\n",
    "            with open('ref_outfile', 'wb') as fp:\n",
    "                pickle.dump(ref_data, fp)\n",
    "                \n",
    "            return print('--- Hello, Reference Image & Encoding Set, Run Code Again. ---')\n",
    "        \n",
    "        \n",
    "        \n",
    "        set_ref_img()\n",
    "        \n",
    "    return current_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_match():\n",
    "    min_dist = 0.4\n",
    "    # input reference image encoding\n",
    "    with open ('ref_outfile', 'rb') as fp:\n",
    "        ref_encoding = pickle.load(fp)\n",
    "    # reference encoding - current encoding  \n",
    "    dist = np.linalg.norm(ref_encoding - current_encoding)\n",
    "    #print(dist)\n",
    "    #print(ref_encoding)\n",
    "    #print(current_encoding)\n",
    "    \n",
    "    if dist <= min_dist:\n",
    "            #min_dist = dist\n",
    "            print(dist)\n",
    "            print('***** VERIFIED, HELLO ROHAN *****')\n",
    "            \n",
    "    else:\n",
    "        print(dist) \n",
    "        print('***** SORRY, WRONG FACE DETECTED *****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1069.9036011695862 seconds checking reference image ---\n",
      "--- Hit Space Bar to take Image ---\n",
      "***** Your Image Taken for Verification !! *****\n",
      "--- Space Bar hit, closing... ---\n"
     ]
    }
   ],
   "source": [
    "current_encoding = check_ref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34946156\n",
      "***** VERIFIED, HELLO ROHAN *****\n"
     ]
    }
   ],
   "source": [
    "image_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09510703  0.0364745   0.04894124  0.07106677 -0.00177835  0.2638341\n",
      "   0.09329543 -0.03184133 -0.00178852 -0.17172755 -0.0110873   0.00825094\n",
      "   0.03492448 -0.13945241  0.05508961 -0.12564279 -0.10994241 -0.01246609\n",
      "  -0.1099332   0.0586728   0.0564166   0.01390411 -0.00458518  0.11288745\n",
      "  -0.02799224 -0.13535368 -0.16765322 -0.19189493 -0.10492426  0.02017349\n",
      "   0.09567601  0.02446495 -0.09006646  0.14849417  0.09360128  0.03639157\n",
      "   0.07654723  0.03407998 -0.06199952 -0.05100162  0.13982804 -0.10484137\n",
      "  -0.028921   -0.05619259 -0.106072   -0.06186314  0.0800312   0.00953437\n",
      "  -0.13266735  0.12887488 -0.05015448 -0.13996527  0.10909993  0.06888076\n",
      "   0.08784179  0.0330603  -0.06345154  0.073434   -0.03934164 -0.12343239\n",
      "  -0.10378136  0.13554272  0.09358464 -0.27275747  0.08842606  0.06917526\n",
      "   0.11543183 -0.09151895 -0.17908487  0.01813965 -0.02668591 -0.00445329\n",
      "  -0.03476192  0.06891561  0.04592307 -0.00107481 -0.02543266 -0.10013514\n",
      "   0.07578135  0.10515255 -0.03209903 -0.00806509 -0.02845797 -0.09494605\n",
      "  -0.02670428  0.05177186  0.03136183 -0.05409369 -0.08846393  0.12649849\n",
      "   0.19623491 -0.18502277  0.04946066 -0.03167771 -0.13198741  0.00916454\n",
      "   0.00991465  0.00433777  0.02153385  0.06055219  0.05586099  0.04191495\n",
      "  -0.07302646  0.03577652 -0.04813786  0.05534441 -0.01031429  0.03390473\n",
      "  -0.15810148  0.06928004  0.03976695  0.05033389 -0.02829189 -0.0984517\n",
      "   0.00135472  0.04451875 -0.08843274 -0.00300382  0.00091282  0.09114408\n",
      "   0.06553867 -0.0619977   0.02964235  0.07710292  0.07962707  0.04103952\n",
      "   0.06142317 -0.06387945]]\n"
     ]
    }
   ],
   "source": [
    "# with open('ref_outfile', 'rb') as fp:\n",
    "#     ref_encoding = pickle.load(fp)\n",
    "# print(ref_encoding)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09510703  0.0364745   0.04894124  0.07106677 -0.00177835  0.2638341\n",
      "   0.09329543 -0.03184133 -0.00178852 -0.17172755 -0.0110873   0.00825094\n",
      "   0.03492448 -0.13945241  0.05508961 -0.12564279 -0.10994241 -0.01246609\n",
      "  -0.1099332   0.0586728   0.0564166   0.01390411 -0.00458518  0.11288745\n",
      "  -0.02799224 -0.13535368 -0.16765322 -0.19189493 -0.10492426  0.02017349\n",
      "   0.09567601  0.02446495 -0.09006646  0.14849417  0.09360128  0.03639157\n",
      "   0.07654723  0.03407998 -0.06199952 -0.05100162  0.13982804 -0.10484137\n",
      "  -0.028921   -0.05619259 -0.106072   -0.06186314  0.0800312   0.00953437\n",
      "  -0.13266735  0.12887488 -0.05015448 -0.13996527  0.10909993  0.06888076\n",
      "   0.08784179  0.0330603  -0.06345154  0.073434   -0.03934164 -0.12343239\n",
      "  -0.10378136  0.13554272  0.09358464 -0.27275747  0.08842606  0.06917526\n",
      "   0.11543183 -0.09151895 -0.17908487  0.01813965 -0.02668591 -0.00445329\n",
      "  -0.03476192  0.06891561  0.04592307 -0.00107481 -0.02543266 -0.10013514\n",
      "   0.07578135  0.10515255 -0.03209903 -0.00806509 -0.02845797 -0.09494605\n",
      "  -0.02670428  0.05177186  0.03136183 -0.05409369 -0.08846393  0.12649849\n",
      "   0.19623491 -0.18502277  0.04946066 -0.03167771 -0.13198741  0.00916454\n",
      "   0.00991465  0.00433777  0.02153385  0.06055219  0.05586099  0.04191495\n",
      "  -0.07302646  0.03577652 -0.04813786  0.05534441 -0.01031429  0.03390473\n",
      "  -0.15810148  0.06928004  0.03976695  0.05033389 -0.02829189 -0.0984517\n",
      "   0.00135472  0.04451875 -0.08843274 -0.00300382  0.00091282  0.09114408\n",
      "   0.06553867 -0.0619977   0.02964235  0.07710292  0.07962707  0.04103952\n",
      "   0.06142317 -0.06387945]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
