{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.7114512920379639 seconds importing libraries ---\n",
      "--- 1.8381133079528809 seconds to import other files ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from keras import backend as K\n",
    "from multiprocessing.dummy import Pool\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "print(\"--- %s seconds importing libraries ---\" % (time.time() - start_time))\n",
    "\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "capture_current_image = False\n",
    "ref_data = {}\n",
    "\n",
    "print(\"--- %s seconds to import other files ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.094399690628052 seconds to load model ---\n",
      "--- 5.124319791793823 seconds to compile model ---\n",
      "--- 74.59939622879028 seconds to load weights ---\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))  #(3, 196, 196)\n",
    "print(\"--- %s seconds to load model ---\" % (time.time() - start_time))\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "print(\"--- %s seconds to compile model ---\" % (time.time() - start_time))\n",
    "\n",
    "load_weights_from_FaceNet(FRmodel)\n",
    "print(\"--- %s seconds to load weights ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PRESENT IMAGE \n",
    "\n",
    "def capture_img():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    cv2.namedWindow(\"Live Frame\")\n",
    "    print(\"--- Hit Space Bar to take Image ---\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        cv2.imshow(\"Live Frame\", frame)\n",
    "        if not ret:\n",
    "            break\n",
    "        k = cv2.waitKey(1)\n",
    "        \n",
    "        if k%256 == 32: #remove this if image to be taken automatically\n",
    "            # SPACE pressed\n",
    "            img_name = \"Your_present_Image_1.jpg\"\n",
    "            ref_img = cv2.imwrite(img_name, frame)\n",
    "            print(\"***** Your Image Taken for Verification !! *****\")\n",
    "        \n",
    "            print(\"--- Space Bar hit, closing... ---\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    your_image1 = cv2.imread('Your_present_Image_1.jpg', 1)\n",
    "    face_cascade1 = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    face1 = face_cascade1.detectMultiScale(your_image1, 1.3, 5)  ##\n",
    "\n",
    "    for (x,y,w,h) in face1:\n",
    "        imgg = cv2.rectangle(your_image1,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "        #roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color1 = imgg[y:y+h, x:x+w]\n",
    "        roi_color1 = cv2.resize(roi_color1, (96, 96))\n",
    "        cv2.imwrite('Your_present_img.jpg',roi_color1)\n",
    "        # get encoding\n",
    "        current_encoding = img_to_encoding(roi_color1, FRmodel)\n",
    "        \n",
    "    return current_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK IF REFERENCE IMAGE PRESENT IN DIRECTORY, ELSE SET REF IMAGE AND ITS ENCODING\n",
    "\n",
    "def check_ref():\n",
    "    \n",
    "    if os.path.isfile('C:/Users/RS_Vulcan/face_recognition/Your_ref_Image.jpg') is True:\n",
    "        print(\"--- %s seconds checking reference image ---\" % (time.time() - start_time))\n",
    "        current_encoding = capture_img()\n",
    "    else:\n",
    "        #SET REFERENCE IMAGE\n",
    "        def set_ref_img(): \n",
    "            cam = cv2.VideoCapture(0)\n",
    "\n",
    "            cv2.namedWindow(\"Live Frame\")\n",
    "            print(\"--- Hit Space Bar to take Image ---\")\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cam.read()\n",
    "                cv2.imshow(\"Live Frame\", frame)\n",
    "                if not ret:\n",
    "                    break\n",
    "                k = cv2.waitKey(1)\n",
    "\n",
    "                if k%256 == 32:\n",
    "                    # SPACE pressed\n",
    "                    img_name = \"Your_ref_Image_1.jpg\"\n",
    "                    ref_img = cv2.imwrite(img_name, frame)\n",
    "                    print(\"***** Your Reference Image Set !! *****\")\n",
    "        \n",
    "                    print(\"--- Space Bar hit, closing... ---\")\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "                    \n",
    "            your_image = cv2.imread('Your_ref_Image_1.jpg', 1)\n",
    "            face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "            face = face_cascade.detectMultiScale(your_image, 1.3, 5)\n",
    "\n",
    "            for (x,y,w,h) in face:\n",
    "                img = cv2.rectangle(your_image,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                roi_color = cv2.resize(roi_color, (96, 96))\n",
    "                cv2.imwrite('Your_ref_Image.jpg',roi_color)\n",
    "                # get encoding\n",
    "                ref_data = img_to_encoding(roi_color, FRmodel)\n",
    "            \n",
    "            # save encoding\n",
    "            with open('ref_outfile', 'wb') as fp:\n",
    "                pickle.dump(ref_data, fp)\n",
    "                \n",
    "            return print('--- Hello, Reference Image & Encoding Set, Run Code Again. ---')\n",
    "        \n",
    "        set_ref_img()\n",
    "        \n",
    "    return current_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_match():\n",
    "    min_dist = 0.5\n",
    "    # input reference image encoding\n",
    "    with open ('ref_outfile', 'rb') as fp:\n",
    "        ref_encoding = pickle.load(fp)\n",
    "    # reference encoding - current encoding  \n",
    "    dist = np.linalg.norm(ref_encoding - current_encoding) \n",
    "    \n",
    "    if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            print(min_dist)\n",
    "            print('***** VERIFIED, HELLO ROHAN *****')\n",
    "            \n",
    "    else:\n",
    "        print(min_dist) \n",
    "        print('***** SORRY, WRONG FACE DETECTED *****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 312.03313732147217 seconds checking reference image ---\n",
      "--- Hit Space Bar to take Image ---\n",
      "***** Your Image Taken for Verification !! *****\n",
      "--- Space Bar hit, closing... ---\n"
     ]
    }
   ],
   "source": [
    "current_encoding = check_ref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4053047\n",
      "***** VERIFIED, HELLO ROHAN *****\n"
     ]
    }
   ],
   "source": [
    "image_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ref_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
